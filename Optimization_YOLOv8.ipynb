{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3af37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================\n",
    "# Imports y espacio de b√∫squeda\n",
    "#===================================================================\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Definir espacio de hiperpar√°metros\n",
    "param_space = {\n",
    "    \"lr0\": (1e-4, 1e-2),\n",
    "    \"momentum\": (0.85, 0.98),\n",
    "    \"weight_decay\": (1e-6, 1e-3),\n",
    "    \"hsv_s\": (0.0, 0.7),\n",
    "    \"scale\": (0.0, 1.0),\n",
    "    \"translate\": (0.0, 0.2)\n",
    "}\n",
    "param_keys = list(param_space.keys())\n",
    "dim = len(param_keys)\n",
    "\n",
    "def sample_particle():\n",
    "    return np.array([np.random.uniform(low, high) for low, high in param_space.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac552782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================\n",
    "# Baseline (con Hiperpar√°metros por defecto)\n",
    "#===================================================================\n",
    "\n",
    "def run_baseline_training(epochs=5, imgsz=640):\n",
    "    \"\"\"\n",
    "    Entrena un modelo YOLOv8 con hiperpar√°metros por defecto\n",
    "    para establecer una l√≠nea de base (baseline) de rendimiento.\n",
    "\n",
    "    Retorna:\n",
    "        float: El score mAP50-95 del modelo baseline.\n",
    "    \"\"\"\n",
    "    print(\"--- Iniciando Entrenamiento Baseline ---\")\n",
    "    print(f\"Entrenando con {epochs} √©pocas y tama√±o de imagen {imgsz}...\")\n",
    "    \n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    # Entrena con los valores por defecto, guardando en una carpeta espec√≠fica\n",
    "    model.train(\n",
    "        data=\"data.yaml\",\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        verbose=True, # Mantenlo en True para ver el progreso claramente\n",
    "        name='baseline_training' # Nombra la carpeta de resultados para claridad\n",
    "    ) \n",
    "\n",
    "    # Valida y obt√©n las m√©tricas\n",
    "    metrics = model.val()\n",
    "    baseline_map = metrics.box.map\n",
    "\n",
    "    print(\"\\n--- Entrenamiento Baseline Finalizado ---\")\n",
    "    print(f\"Baseline mAP50-95: {baseline_map:.4f}\")\n",
    "    \n",
    "    return baseline_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "# Funci√≥n de evaluaci√≥n (fitness)\n",
    "#====================================================================\n",
    "\n",
    "def evaluate_particle(position, epochs=5, imgsz=640):\n",
    "    \"\"\"Entrena YOLO con hiperpar√°metros de una part√≠cula y devuelve fitness.\"\"\"\n",
    "    cfg = {k: float(v) for k, v in zip(param_keys, position)}\n",
    "\n",
    "    overrides = dict(\n",
    "        data=\"data.yaml\",\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=16,\n",
    "        optimizer=\"AdamW\",\n",
    "        lr0=cfg[\"lr0\"],\n",
    "        momentum=cfg[\"momentum\"],\n",
    "        weight_decay=cfg[\"weight_decay\"],\n",
    "        hsv_s=cfg[\"hsv_s\"],\n",
    "        scale=cfg[\"scale\"],\n",
    "        translate=cfg[\"translate\"],\n",
    "        #device=0,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    model.train(**overrides)\n",
    "    metrics = model.val()\n",
    "\n",
    "    fitness = metrics.box.map  # mAP50-95\n",
    "    return fitness, cfg, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d008b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================\n",
    "# Metaheur√≠sticas\n",
    "#===================================================================\n",
    "\n",
    "# PSO\n",
    "def iterarPSO(maxIter, iter, dim, population, best, pBest, vel, ub0):\n",
    "    Vmax = ub0 * 0.1\n",
    "    wMax, wMin = 0.9, 0.1\n",
    "    c1, c2 = 2, 2\n",
    "\n",
    "    w = wMax - iter * ((wMax - wMin) / maxIter)\n",
    "    r1 = np.random.rand(population.shape[0], dim)\n",
    "    r2 = np.random.rand(population.shape[0], dim)\n",
    "\n",
    "    vel = (\n",
    "        w * vel\n",
    "        + c1 * r1 * (pBest - population)\n",
    "        + c2 * r2 * (best - population)\n",
    "    )\n",
    "    vel = np.clip(vel, -Vmax, Vmax)\n",
    "    population = population + vel\n",
    "    return population, vel\n",
    "\n",
    "# WOA\n",
    "import math, random\n",
    "def iterarWOA(maxIter, iter, dim, population, best):\n",
    "    a = 2 - (2 * iter / maxIter)\n",
    "    b = 1\n",
    "    new_population = []\n",
    "\n",
    "    for individual in population:\n",
    "        p = random.uniform(0, 1)\n",
    "        r = random.uniform(0, 1)\n",
    "        l = random.uniform(-1, 1)\n",
    "        A = 2 * a * r - a\n",
    "        C = 2 * random.uniform(0, 1)\n",
    "\n",
    "        if p < 0.5:\n",
    "            if abs(A) < 1:  # encircle best\n",
    "                D = [abs(C * best[j] - individual[j]) for j in range(dim)]\n",
    "                new_individual = [best[j] - A * D[j] for j in range(dim)]\n",
    "            else:  # random search\n",
    "                rand_idx = random.randint(0, len(population) - 1)\n",
    "                rand_ind = population[rand_idx]\n",
    "                D = [abs(C * rand_ind[j] - individual[j]) for j in range(dim)]\n",
    "                new_individual = [rand_ind[j] - A * D[j] for j in range(dim)]\n",
    "        else:  # spiral update\n",
    "            D_prime = [best[j] - individual[j] for j in range(dim)]\n",
    "            spiral_component = math.exp(b * l) * math.cos(2 * math.pi * l)\n",
    "            new_individual = [D_prime[j] * spiral_component + best[j] for j in range(dim)]\n",
    "\n",
    "        new_population.append(new_individual)\n",
    "    return np.array(new_population)\n",
    "\n",
    "# GWO\n",
    "def iterarGWO(maxIter, iter, dim, population, fitness):\n",
    "    n_individuos = population.shape[0]\n",
    "    new_population = np.zeros_like(population)\n",
    "\n",
    "    # Ordenar por fitness \n",
    "    sorted_indices = np.argsort(fitness)[::-1]\n",
    "    alpha = population[sorted_indices[0]]\n",
    "    beta = population[sorted_indices[1]]\n",
    "    delta = population[sorted_indices[2]]\n",
    "\n",
    "    # Par√°metro de control \"a\" (decrece linealmente)\n",
    "    a = 2 - iter * (2 / maxIter)\n",
    "\n",
    "    for i in range(n_individuos):\n",
    "        wolf = population[i]\n",
    "        new_wolf = np.zeros(dim)\n",
    "\n",
    "        for j in range(dim):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            A1, C1 = 2 * a * r1 - a, 2 * r2\n",
    "            D_alpha = abs(C1 * alpha[j] - wolf[j])\n",
    "            X1 = alpha[j] - A1 * D_alpha\n",
    "\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            A2, C2 = 2 * a * r1 - a, 2 * r2\n",
    "            D_beta = abs(C2 * beta[j] - wolf[j])\n",
    "            X2 = beta[j] - A2 * D_beta\n",
    "\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            A3, C3 = 2 * a * r1 - a, 2 * r2\n",
    "            D_delta = abs(C3 * delta[j] - wolf[j])\n",
    "            X3 = delta[j] - A3 * D_delta\n",
    "\n",
    "            # Promedio de las 3 gu√≠as\n",
    "            new_wolf[j] = (X1 + X2 + X3) / 3\n",
    "\n",
    "        new_population[i] = new_wolf\n",
    "\n",
    "    return new_population\n",
    "\n",
    "# GWO\n",
    "def iterarGWO(maxIter, iter, dim, population, fitness):\n",
    "    population = np.array(population)\n",
    "    fitness = np.array(fitness)\n",
    "\n",
    "    # Par√°metro 'a' decrece linealmente de 2 a 0\n",
    "    a = 2 - iter * (2 / maxIter)\n",
    "\n",
    "    # Ordenar posiciones seg√∫n fitness (descendente para maximizar)\n",
    "    sorted_indices = np.argsort(fitness)[::-1]\n",
    "\n",
    "    # Alpha, Beta, Delta wolves\n",
    "    Xalfa = population[sorted_indices[0]]\n",
    "    Xbeta = population[sorted_indices[1]]\n",
    "    Xdelta = population[sorted_indices[2]]\n",
    "\n",
    "    # Random values para todos los c√°lculos\n",
    "    r1 = np.random.uniform(0.0, 1.0, (population.shape[0], dim, 3))\n",
    "    r2 = np.random.uniform(0.0, 1.0, (population.shape[0], dim, 3))\n",
    "\n",
    "    # Calcular A y C\n",
    "    A = 2 * a * r1 - a\n",
    "    C = 2 * r2\n",
    "\n",
    "    # Distancias a los 3 lobos l√≠deres\n",
    "    d_alfa = np.abs(C[:, :, 0] * Xalfa - population)\n",
    "    d_beta = np.abs(C[:, :, 1] * Xbeta - population)\n",
    "    d_delta = np.abs(C[:, :, 2] * Xdelta - population)\n",
    "\n",
    "    # Actualizaci√≥n de posiciones\n",
    "    X1 = Xalfa - A[:, :, 0] * d_alfa\n",
    "    X2 = Xbeta - A[:, :, 1] * d_beta\n",
    "    X3 = Xdelta - A[:, :, 2] * d_delta\n",
    "\n",
    "    # Promedio de las 3 gu√≠as\n",
    "    population = (X1 + X2 + X3) / 3\n",
    "\n",
    "    return population\n",
    "\n",
    "#FA\n",
    "\n",
    "def iterarFA(maxIter, iter, dim, population, fitness, alpha=0.5, beta0=1.0, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Implementaci√≥n simple del Firefly Algorithm para tu marco de optimizaci√≥n.\n",
    "    - population: matriz (n_individuos, dim)\n",
    "    - fitness: lista o array con el valor de cada individuo\n",
    "    - alpha: factor de aleatoriedad\n",
    "    - beta0: atractividad base\n",
    "    - gamma: coeficiente de absorci√≥n de luz\n",
    "    \"\"\"\n",
    "    n_fireflies = population.shape[0]\n",
    "    new_population = np.copy(population)\n",
    "    fitness = np.array(fitness)\n",
    "\n",
    "    # Ordenar luci√©rnagas por brillo (fitness)\n",
    "    sorted_indices = np.argsort(fitness)[::-1]  # descendente (mayor fitness = m√°s brillo)\n",
    "    population = population[sorted_indices]\n",
    "    fitness = fitness[sorted_indices]\n",
    "\n",
    "    # Actualizar cada luci√©rnaga seg√∫n las m√°s brillantes\n",
    "    for i in range(n_fireflies):\n",
    "        for j in range(n_fireflies):\n",
    "            if fitness[j] > fitness[i]:  # luci√©rnaga j m√°s brillante\n",
    "                r = np.linalg.norm(population[i] - population[j])\n",
    "                beta = beta0 * np.exp(-gamma * (r ** 2))\n",
    "                e = np.random.randn(dim)\n",
    "                # Movimiento\n",
    "                new_population[i] += beta * (population[j] - population[i]) + alpha * e\n",
    "\n",
    "    # Retornar nueva poblaci√≥n\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================\n",
    "# Loop general de optimizaci√≥n\n",
    "#===================================================================\n",
    "\n",
    "def run_metaheuristic(name=\"PSO\", n_particles=4, max_iter=3):\n",
    "    population = np.array([sample_particle() for _ in range(n_particles)])\n",
    "    vel = np.zeros_like(population)\n",
    "    pBest, pBest_scores = np.copy(population), np.full(n_particles, -np.inf)\n",
    "    gBest, gBest_score = None, -np.inf\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        print(f\"\\nIteraci√≥n {it+1}/{max_iter}\")\n",
    "        for i, particle in enumerate(population):\n",
    "            fitness, cfg, metrics = evaluate_particle(particle, epochs=5)\n",
    "\n",
    "            if fitness > pBest_scores[i]:\n",
    "                pBest[i] = particle\n",
    "                pBest_scores[i] = fitness\n",
    "            if fitness > gBest_score:\n",
    "                gBest, gBest_score = particle, fitness\n",
    "\n",
    "            history.append({\"iter\": it, \"particle\": i, \"fitness\": fitness, \"cfg\": cfg})\n",
    "\n",
    "        # Elegir algoritmo\n",
    "        if name == \"PSO\":\n",
    "            ub0 = np.array([high for _, high in param_space.values()])\n",
    "            population, vel = iterarPSO(max_iter, it, dim, population, gBest, pBest, vel, ub0)\n",
    "        elif name == \"WOA\":\n",
    "            population = iterarWOA(max_iter, it, dim, population, gBest)\n",
    "        elif name == \"GWO\":\n",
    "            population = iterarGWO(max_iter, it, dim, population, history)\n",
    "        elif name == \"FA\":\n",
    "            current_fitness = [h[\"fitness\"] for h in history if h[\"iter\"] == it]\n",
    "            population = iterarFA(max_iter, it, dim, population, current_fitness)\n",
    "            \n",
    "        # Clipping a los rangos definidos\n",
    "        for i in range(population.shape[0]):\n",
    "            for j, (low, high) in enumerate(param_space.values()):\n",
    "                population[i, j] = np.clip(population[i, j], low, high)\n",
    "\n",
    "        print(f\"  Mejor global hasta ahora: {gBest_score:.4f}\")\n",
    "\n",
    "    with open(f\"{name}_results.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    return gBest, gBest_score, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621aa7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO EXPERIMENTO: OBTENIENDO BASELINE\n",
      "==================================================\n",
      "--- Iniciando Entrenamiento Baseline ---\n",
      "Entrenando con 2 √©pocas y tama√±o de imagen 640...\n",
      "Ultralytics 8.3.203 üöÄ Python-3.13.2 torch-2.8.0 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=baseline_training2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=21\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    755407  ultralytics.nn.modules.head.Detect           [21, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,014,943 parameters, 3,014,927 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1048.7¬±920.4 MB/s, size: 42.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/train/labels.cache... 2704 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2704/2704 6.3Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1837.3¬±975.8 MB/s, size: 45.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/labels.cache... 300 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 1.3Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/images/Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/images/Pias--360-_PNG.rf.8405b0e44009a9300e0a1100ccf7d5b3.jpg: 7 duplicate labels removed\n",
      "Plotting labels to /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0004, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/2         0G      1.516      3.401      1.175        218        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 169/169 0.2it/s 16:516.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 0.4it/s 26.6s.1ss\n",
      "                   all        300       2568      0.461      0.144      0.121      0.071\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/2         0G      1.474       2.26      1.158        362        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 169/169 0.2it/s 17:256.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 0.4it/s 26.0s.0ss\n",
      "                   all        300       2568      0.575      0.179      0.181      0.109\n",
      "\n",
      "2 epochs completed in 0.586 hours.\n",
      "Optimizer stripped from /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2/weights/best.pt...\n",
      "Ultralytics 8.3.203 üöÄ Python-3.13.2 torch-2.8.0 CPU (Apple M2)\n",
      "Model summary (fused): 72 layers, 3,009,743 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 0.4it/s 24.3s.7ss\n",
      "                   all        300       2568      0.576      0.179      0.181      0.109\n",
      "               bicycle         30         32          1          0     0.0217    0.00686\n",
      "                   bus        220        425      0.548      0.431      0.471      0.326\n",
      "                   car        232        842      0.604      0.714       0.66      0.415\n",
      "               minibus          2          2          1          0          0          0\n",
      "               minivan         87        110          0          0     0.0847     0.0509\n",
      "             motorbike        166        335      0.513      0.346      0.327     0.0897\n",
      "                pickup        105        142       0.22     0.0634        0.1     0.0621\n",
      "             policecar          1          1          1          0          0          0\n",
      "              rickshaw         62        192      0.388      0.406      0.388      0.234\n",
      "               scooter          1          1          1          0          0          0\n",
      "                   suv         49         60     0.0785      0.117     0.0458     0.0301\n",
      "                  taxi         18         19          1          0      0.003     0.0024\n",
      "  three wheelers -CNG-        148        252      0.598      0.336      0.425      0.292\n",
      "                 truck         53         84      0.267      0.452      0.313      0.205\n",
      "                   van         52         62          0          0     0.0565     0.0342\n",
      "           wheelbarrow          9          9          1          0     0.0023    0.00046\n",
      "Speed: 0.4ms preprocess, 73.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training2\u001b[0m\n",
      "Ultralytics 8.3.203 üöÄ Python-3.13.2 torch-2.8.0 CPU (Apple M2)\n",
      "Model summary (fused): 72 layers, 3,009,743 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 904.6¬±237.5 MB/s, size: 30.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/labels.cache... 300 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 1.7Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/images/Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/images/Pias--360-_PNG.rf.8405b0e44009a9300e0a1100ccf7d5b3.jpg: 7 duplicate labels removed\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 0.7it/s 27.1s1.5ss\n",
      "                   all        300       2568      0.576      0.179      0.181      0.109\n",
      "               bicycle         30         32          1          0     0.0217    0.00686\n",
      "                   bus        220        425      0.548      0.431      0.471      0.326\n",
      "                   car        232        842      0.604      0.714       0.66      0.415\n",
      "               minibus          2          2          1          0          0          0\n",
      "               minivan         87        110          0          0     0.0847     0.0509\n",
      "             motorbike        166        335      0.513      0.346      0.327     0.0897\n",
      "                pickup        105        142       0.22     0.0634        0.1     0.0621\n",
      "             policecar          1          1          1          0          0          0\n",
      "              rickshaw         62        192      0.388      0.406      0.388      0.234\n",
      "               scooter          1          1          1          0          0          0\n",
      "                   suv         49         60     0.0785      0.117     0.0458     0.0301\n",
      "                  taxi         18         19          1          0      0.003     0.0024\n",
      "  three wheelers -CNG-        148        252      0.598      0.336      0.425      0.292\n",
      "                 truck         53         84      0.267      0.452      0.313      0.205\n",
      "                   van         52         62          0          0     0.0565     0.0342\n",
      "           wheelbarrow          9          9          1          0     0.0023    0.00046\n",
      "Speed: 0.4ms preprocess, 85.7ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/baseline_training22\u001b[0m\n",
      "\n",
      "--- Entrenamiento Baseline Finalizado ---\n",
      "Baseline mAP50-95: 0.1093\n",
      "\n",
      "El score a superar es: 0.1093\n",
      "\n",
      "\n",
      "INICIANDO OPTIMIZACI√ìN CON 'GWO'\n",
      "==================================================\n",
      "\n",
      "Iteraci√≥n 1/2\n",
      "Ultralytics 8.3.203 üöÄ Python-3.13.2 torch-2.8.0 CPU (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.3212665180317149, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.007161766002709006, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.9539233006304597, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.3140009589988261, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.11272933389852963, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.00087502030253942, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=21\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    755407  ultralytics.nn.modules.head.Detect           [21, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,014,943 parameters, 3,014,927 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 458.0¬±469.6 MB/s, size: 42.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/train/labels.cache... 2704 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2704/2704 8.7Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1492.9¬±1066.5 MB/s, size: 45.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/labels.cache... 300 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 300/300 1.3Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/images/Pias--359-_PNG.rf.43bcf36efe5cf8c37552d2c45fffea60.jpg: 9 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/dataset/valid/images/Pias--360-_PNG.rf.8405b0e44009a9300e0a1100ccf7d5b3.jpg: 7 duplicate labels removed\n",
      "Plotting labels to /Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.007161766002709006, momentum=0.9539233006304597) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00087502030253942), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/fabianapinavera/Desktop/hybrid-vehicle-yolo/runs/detect/train\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/5         0G      1.579      3.646      1.254        162        640: 14% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 23/169 0.2it/s 2:30<15:04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m algo_name \u001b[38;5;129;01min\u001b[39;00m algorithms_to_test:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mINICIANDO OPTIMIZACI√ìN CON \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     best_cfg, best_score, hist = \u001b[43mrun_metaheuristic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_particles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_iterations\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Guarda los resultados de este algoritmo\u001b[39;00m\n\u001b[32m     33\u001b[39m     all_results[algo_name] = {\n\u001b[32m     34\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m: best_score,\n\u001b[32m     35\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(param_keys, best_cfg)) \u001b[38;5;66;03m# Guardamos como dict para m√°s claridad\u001b[39;00m\n\u001b[32m     36\u001b[39m     }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mrun_metaheuristic\u001b[39m\u001b[34m(name, n_particles, max_iter)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIteraci√≥n \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mit+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, particle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(population):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     fitness, cfg, metrics = \u001b[43mevaluate_particle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fitness > pBest_scores[i]:\n\u001b[32m     19\u001b[39m         pBest[i] = particle\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mevaluate_particle\u001b[39m\u001b[34m(position, epochs, imgsz)\u001b[39m\n\u001b[32m      9\u001b[39m overrides = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     10\u001b[39m     data=\u001b[33m\"\u001b[39m\u001b[33mdata.yaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     epochs=epochs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m model = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolov8n.pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m metrics = model.val()\n\u001b[32m     29\u001b[39m fitness = metrics.box.map  \u001b[38;5;66;03m# mAP50-95\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/ultralytics/engine/model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/ultralytics/engine/trainer.py:235\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    232\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/ultralytics/engine/trainer.py:432\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    427\u001b[39m     \u001b[38;5;28mself\u001b[39m.tloss = (\n\u001b[32m    428\u001b[39m         (\u001b[38;5;28mself\u001b[39m.tloss * i + \u001b[38;5;28mself\u001b[39m.loss_items) / (i + \u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss_items\n\u001b[32m    429\u001b[39m     )\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#===================================================================\n",
    "# Ejecuci√≥n Maestra del Experimento\n",
    "#===================================================================\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL EXPERIMENTO ---\n",
    "# Define aqu√≠ todos los algoritmos que quieres probar\n",
    "algorithms_to_test = [\"FA\"]\n",
    "num_particles = 10\n",
    "num_iterations = 10\n",
    "num_epochs = 5\n",
    "\n",
    "# Diccionario para guardar todos los resultados\n",
    "all_results = {}\n",
    "\n",
    "\n",
    "# --- PASO 1: Establecer la l√≠nea de base (baseline) UNA SOLA VEZ ---\n",
    "print(\"INICIANDO EXPERIMENTO: OBTENIENDO BASELINE\\n\" + \"=\"*50)\n",
    "baseline_score = run_baseline_training(epochs=num_epochs)\n",
    "print(f\"\\nEl score a superar es: {baseline_score:.4f}\\n\")\n",
    "\n",
    "\n",
    "# --- PASO 2: Bucle para ejecutar cada metaheur√≠stica ---\n",
    "for algo_name in algorithms_to_test:\n",
    "    print(f\"\\nINICIANDO OPTIMIZACI√ìN CON '{algo_name}'\\n\" + \"=\"*50)\n",
    "    \n",
    "    best_cfg, best_score, hist = run_metaheuristic(\n",
    "        name=algo_name, \n",
    "        n_particles=num_particles, \n",
    "        max_iter=num_iterations\n",
    "    )\n",
    "    \n",
    "    # Guarda los resultados de este algoritmo\n",
    "    all_results[algo_name] = {\n",
    "        'score': best_score,\n",
    "        'config': dict(zip(param_keys, best_cfg)) # Guardamos como dict para m√°s claridad\n",
    "    }\n",
    "    print(f\"--- Optimizaci√≥n con '{algo_name}' finalizada. Mejor score: {best_score:.4f} ---\")\n",
    "\n",
    "\n",
    "# --- PASO 3: Mostrar un resumen final comparativo ---\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"--- RESUMEN FINAL DEL EXPERIMENTO ---\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nBaseline mAP50-95 (Default): {baseline_score:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Imprimir los resultados de cada algoritmo y su mejora\n",
    "for algo_name, result in all_results.items():\n",
    "    score = result['score']\n",
    "    improvement = ((score - baseline_score) / baseline_score) * 100\n",
    "    \n",
    "    print(f\"\\nAlgoritmo: {algo_name}\")\n",
    "    print(f\"  - Mejor mAP50-95: {score:.4f}\")\n",
    "    print(f\"  - Mejora sobre Baseline: {improvement:.2f}%\")\n",
    "    print(\"  - Mejor Configuraci√≥n:\")\n",
    "    for k, v in result['config'].items():\n",
    "        print(f\"    {k}: {v:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- FIN DEL EXPERIMENTO ---\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
